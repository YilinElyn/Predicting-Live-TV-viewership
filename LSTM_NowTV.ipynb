{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vudWLsxG5I4"
      },
      "source": [
        "## LSTM_NowTV\n",
        "## Table of Contents:\n",
        "* [0. Importing dependencies](#dependencies)\n",
        "* [1. Setting up of the dataset](#1.0)\n",
        "    * [1.1 Importing of the dataset](#1.1)\n",
        "    * [1.2 Splitting of the dataset](#1.2)\n",
        "* [2. Model Implementation](#2.0)\n",
        "    * [2.2 Model training](#2.1)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This LSTM model implements multi-task output and predicts future 24-hour viewership by applying a rolling window.\n",
        "\n",
        "Although the results from the first five epochs suggest that this optimized LSTM model has surpassed last year's model in terms of prediction accuracy, it has proven to be inefficient whether running on Google Colab or on the company's remote server. This inefficiency is believed to be due to the high computational demand caused by the excessively fine granularity and large volume of data. Therefore, given the current computing resources available, the project has decided to temporarily abandon the use of the LSTM model as a forecasting model.\n",
        "\n",
        "Nonetheless, this file has been uploaded to the repository for record and reference."
      ],
      "metadata": {
        "id": "PY7r67GvFhqF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTTgeAuyYm7f"
      },
      "source": [
        "# 0. Importing dependencies  <a class=\"anchor\" id=\"dependencies\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "kSzFQaPEFPXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNiL8pJ-Zc9r"
      },
      "source": [
        "# 1. Setting up of the dataset <a class=\"anchor\" id=\"1.0\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tyNPwfqZkt6"
      },
      "source": [
        "## 1.1 Importing of the dataset <a class=\"anchor\" id=\"1.1\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCU8bEC9GuiI",
        "outputId": "4a8a1a9f-58d2-49e2-8ebd-65795babb795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['trend_vc', 'yearly_vc', 'weekly_vc', 'trend_i', 'yearly_i', 'weekly_i',\n",
            "       'trend_ud', 'yearly_ud', 'weekly_ud', 'videoConsumption', 'impression'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Load the final dataframe\n",
        "file_path = '/content/gdrive/My Drive/df_final.csv'\n",
        "df_final = pd.read_csv(file_path)\n",
        "\n",
        "print(df_final.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqF3ku_vZ2hN"
      },
      "source": [
        "## 1.2 Splitting the dataset <a class=\"anchor\" id=\"1.2\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keDF4rR5J6Mq"
      },
      "outputs": [],
      "source": [
        "def split_dataset(df):\n",
        "    # Divide the data into 70% for the training set, 15% for the validation set, and 15% for the test set\n",
        "    idx_train_end = round(0.7 * len(df))\n",
        "    idx_val_end = round(0.85 * len(df))\n",
        "\n",
        "    # Split the DataFrame into training, validation, and test sets\n",
        "    df_train = df.iloc[:idx_train_end]\n",
        "    df_val = df.iloc[idx_train_end:idx_val_end]\n",
        "    df_test = df.iloc[idx_val_end:]\n",
        "\n",
        "    return df_train, df_val, df_test\n",
        "\n",
        "# Conduct dataset splitting on df_final\n",
        "df_train, df_val, df_test = split_dataset(df_final)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EOWp-LgaVN_"
      },
      "source": [
        "#2. Model Implementation <a class=\"anchor\" id=\"2.0\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBAUkM3Eg290"
      },
      "source": [
        "## 2.1 Model training <a class=\"anchor\" id=\"2.1\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJ87WhwqbUas"
      },
      "outputs": [],
      "source": [
        "# Define input features and target outputs\n",
        "features = ['weekly_vc', 'weekly_i', 'weekly_ud']\n",
        "targets = ['videoConsumption', 'impression']\n",
        "number_of_features = len(features)\n",
        "\n",
        "# Selecting features and target columns from\n",
        "train_features = df_train[features + targets]\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "train_scaled = scaler.fit_transform(train_features)\n",
        "\n",
        "# Convert the scaled array back to a DataFrame, keeping the column names\n",
        "train_scaled = pd.DataFrame(train_scaled, columns=features + targets)\n",
        "\n",
        "# Same for val and test set\n",
        "val_features = df_val[features + targets]\n",
        "val_scaled = scaler.transform(val_features)\n",
        "val_scaled = pd.DataFrame(val_scaled, columns=features + targets)\n",
        "\n",
        "test_features = df_test[features + targets]\n",
        "test_scaled = scaler.transform(test_features)\n",
        "test_scaled = pd.DataFrame(test_scaled, columns=features + targets)\n",
        "\n",
        "# Obtain train_data, val_data and test_data\n",
        "train_data = train_scaled.values\n",
        "val_data = val_scaled.values\n",
        "test_data = test_scaled.values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkg1BhUo-_Dj"
      },
      "outputs": [],
      "source": [
        "def rolling_window_generator(data, window_size, forecast_horizon, batch_size=32):\n",
        "    total_size = len(data) - window_size - forecast_horizon + 1\n",
        "    num_batches = total_size // batch_size\n",
        "\n",
        "    while True:\n",
        "        for i in range(num_batches):\n",
        "            start = i * batch_size\n",
        "            end = start + batch_size\n",
        "            batch_X, batch_y_vc, batch_y_i = [], [], []\n",
        "            for j in range(start, end):\n",
        "                batch_X.append(data[j:(j + window_size), :-2])  # Features\n",
        "                # Two dimension outputs\n",
        "                batch_y_vc.append(data[(j + window_size):(j + window_size + forecast_horizon), -2])\n",
        "                batch_y_i.append(data[(j + window_size):(j + window_size + forecast_horizon), -1])\n",
        "            yield np.array(batch_X), [np.array(batch_y_vc), np.array(batch_y_i)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eo0Xz_HPwf4s"
      },
      "outputs": [],
      "source": [
        "# Create Evaluation Metric\n",
        "def rmse(y_true, y_pred):\n",
        "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))\n",
        "\n",
        "def mape(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.abs((y_true - y_pred) / y_true)) * 100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnvxfbqJwavx",
        "outputId": "1ef99efc-c9ac-42db-ef33-845efb22b68b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "34002/34002 [==============================] - 17957s 528ms/step - loss: 0.0160 - videoConsumption_loss: 0.0134 - impression_loss: 0.0026 - videoConsumption_mse: 0.0134 - videoConsumption_rmse: 0.1072 - videoConsumption_mape: inf - impression_mse: 0.0026 - impression_rmse: 0.0493 - impression_mape: inf - val_loss: 0.0159 - val_videoConsumption_loss: 0.0135 - val_impression_loss: 0.0023 - val_videoConsumption_mse: 0.0135 - val_videoConsumption_rmse: 0.1055 - val_videoConsumption_mape: 332.0480 - val_impression_mse: 0.0023 - val_impression_rmse: 0.0461 - val_impression_mape: inf\n",
            "Epoch 2/7\n",
            "34002/34002 [==============================] - 17853s 525ms/step - loss: 0.0170 - videoConsumption_loss: 0.0142 - impression_loss: 0.0028 - videoConsumption_mse: 0.0142 - videoConsumption_rmse: 0.1045 - videoConsumption_mape: inf - impression_mse: 0.0028 - impression_rmse: 0.0480 - impression_mape: inf - val_loss: 0.0152 - val_videoConsumption_loss: 0.0130 - val_impression_loss: 0.0022 - val_videoConsumption_mse: 0.0130 - val_videoConsumption_rmse: 0.1019 - val_videoConsumption_mape: 327.0423 - val_impression_mse: 0.0022 - val_impression_rmse: 0.0448 - val_impression_mape: inf\n",
            "Epoch 3/7\n",
            "34002/34002 [==============================] - 17540s 516ms/step - loss: 0.0138 - videoConsumption_loss: 0.0116 - impression_loss: 0.0021 - videoConsumption_mse: 0.0116 - videoConsumption_rmse: 0.0975 - videoConsumption_mape: inf - impression_mse: 0.0021 - impression_rmse: 0.0443 - impression_mape: inf - val_loss: 0.0144 - val_videoConsumption_loss: 0.0123 - val_impression_loss: 0.0021 - val_videoConsumption_mse: 0.0123 - val_videoConsumption_rmse: 0.0987 - val_videoConsumption_mape: 325.7050 - val_impression_mse: 0.0021 - val_impression_rmse: 0.0437 - val_impression_mape: inf\n",
            "Epoch 4/7\n",
            "34002/34002 [==============================] - 17602s 518ms/step - loss: 0.0122 - videoConsumption_loss: 0.0103 - impression_loss: 0.0019 - videoConsumption_mse: 0.0103 - videoConsumption_rmse: 0.0908 - videoConsumption_mape: inf - impression_mse: 0.0019 - impression_rmse: 0.0412 - impression_mape: inf - val_loss: 0.0140 - val_videoConsumption_loss: 0.0120 - val_impression_loss: 0.0020 - val_videoConsumption_mse: 0.0120 - val_videoConsumption_rmse: 0.0983 - val_videoConsumption_mape: 321.6135 - val_impression_mse: 0.0020 - val_impression_rmse: 0.0429 - val_impression_mape: inf\n",
            "Epoch 5/7\n",
            "28220/34002 [=======================>......] - ETA: 46:51 - loss: 0.0108 - videoConsumption_loss: 0.0091 - impression_loss: 0.0016 - videoConsumption_mse: 0.0091 - videoConsumption_rmse: 0.0854 - videoConsumption_mape: inf - impression_mse: 0.0016 - impression_rmse: 0.0385 - impression_mape: inf"
          ]
        }
      ],
      "source": [
        "# Set h values\n",
        "h = 1440  # 1-Day 1440, 7-Day 10080, 30-Day 43920\n",
        "# number_of_features = 3  # 'weekly_vc', 'weekly_i', 'weekly_ud'\n",
        "\n",
        "input_layer = Input(shape=(h, number_of_features))\n",
        "lstm_layer = LSTM(50, return_sequences=False)(input_layer)\n",
        "\n",
        "# Define two output layers\n",
        "output_vc = Dense(1440, activation='linear', name='videoConsumption')(lstm_layer)\n",
        "output_i = Dense(1440, activation='linear', name='impression')(lstm_layer)\n",
        "\n",
        "# Initialize model\n",
        "model = Model(inputs=input_layer, outputs=[output_vc, output_i])\n",
        "model.compile(optimizer='adam',\n",
        "              loss={'videoConsumption': 'mean_squared_error', 'impression': 'mean_squared_error'},\n",
        "              metrics={'videoConsumption': ['mse', rmse, mape], 'impression': ['mse', rmse, mape]})\n",
        "\n",
        "# Apply rolling window\n",
        "train_gen = rolling_window_generator(train_data, h, 1440, 32)\n",
        "val_gen = rolling_window_generator(val_data, h, 1440, 32)\n",
        "\n",
        "# Calculate steps_per_epoch\n",
        "train_steps = (len(train_data) - h - 1440 + 1) // 32\n",
        "val_steps = (len(val_data) - h - 1440 + 1) // 32\n",
        "\n",
        "# Train model\n",
        "history = model.fit(train_gen, steps_per_epoch=train_steps, epochs=7, validation_data=val_gen, validation_steps=val_steps)\n",
        "\n",
        "# Save model\n",
        "model_save_path = '/content/drive/My Drive/lstm_NowTV_1440.h5'\n",
        "model.save(model_save_path)\n",
        "\n",
        "# Plotting training and validation losses\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['videoConsumption_loss'], label='Train Loss for Video Consumption')\n",
        "plt.plot(history.history['val_videoConsumption_loss'], label='Validation Loss for Video Consumption')\n",
        "plt.title('Video Consumption Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['impression_loss'], label='Train Loss for Impression')\n",
        "plt.plot(history.history['val_impression_loss'], label='Validation Loss for Impression')\n",
        "plt.title('Impression Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Model Evaluation\n",
        "loss_vc, mse_vc, rmse_vc, mape_vc, loss_i, mse_i, rmse_i, mape_i = model.evaluate(val_gen, steps=val_steps)\n",
        "print(f\"Validation loss for Video Consumption (vc)={loss_vc}, RMSE={rmse_vc}, MAPE={mape_vc}\")\n",
        "print(f\"Validation loss for Impression (i)={loss_i}, RMSE={rmse_i}, MAPE={mape_i}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}